# 20210318
## http2.0
优点：
- 对1.x协议语意的完全兼容
  - 2.0协议是在1.x基础上的升级而不是重写，1.x协议的方法、状态及api在2.0协议里是一样的
- 性能的大幅提升
  - 2.0协议重点是对终端用户的感知延迟、网络及服务器资源的使用等性能优化
### 二进制分帧（Binary Format）
http2.0之所以能突破http1.x标准的性能限制，改进传输性能，实现低延迟和高吞吐量，就是因为其新增里二进制分帧层。
- 帧(frame)包含部分：类型Type, 长度Length, 标记Flags, 流标识Stream和frame payload有效载荷。
- 消息(message)：一个完整的请求或者响应，比如请求、响应等，由一个或多个 Frame 组成。
- 流是连接中的一个虚拟信道，可以承载双向消息传输。每个流有唯一整数标识符。为了防止两端流ID冲突，客户端发起的流具有奇数ID，服务器端发起的流具有偶数ID。
- 流标识是描述二进制frame的格式，使得每个frame能够基于http2发送，与流标识联系的是一个流，每个流是一个逻辑联系，一个独立的双向的frame存在于客户端和服务器端之间的http2连接中。一个http2连接上可包含多个并发打开的流，这个并发流的数量能够由客户端设置。

在二进制分帧层上，http2.0会将所有传输信息分割成更小的消息和帧，并对它们采用二进制格式的编码将其封装，新增的二进制分帧层同时也能够保证http的各种动词、方法、首部都不受影响，兼容上一代标准。

其中http1.x中的首部信息header封装到headers帧中，而request body将被封装到Data帧中。

### 多路复用（multiplexing）连接共享
在http1.1中，浏览器客户端在同一时间，针对同一域名下的请求有一定数量的限制。超过限制数目的请求会被阻塞。这也是为何一些站点会有多个静态资源 CDN 域名的原因之一。

有了新的分帧机制后，http/2 不再依赖多个TCP连接去实现多流并行了。每个数据流都拆分成很多互不依赖的帧，而这些帧可以交错（乱序发送），还可以分优先级。

多路复用意味着来自很多流的数据包能够混合在一起通过同样连接传输。当到达终点时，再根据不同的帧首部的流标识符重新连接将不同的数据流进行组装。

http 2.0 连接都是持久化的，而且客户端与服务器之间也只需要一个连接（每个域名一个连接）即可。

### 头部压缩（Header Compression）
http1.x 的头带有大量信息，而且每次都要重复发送。

http2使用encoder（HPACK算法）来减少需要传输的header大小，通讯双方各自缓存一份头部字段表，既避免了重复header的传输，又减小了需要传输的大小。对于相同的数据，不再通过每次请求和响应发送;通信期间几乎不会改变通用键-值对(用户代理、可接受的媒体类型,等等)只需发送一次。事实上,如果请求中不包含首部(例如对同一资源的轮询请求),那么,首部开销就是零字节。此时所有首部都自动使用之前请求发送的首部。如果首部发生了变化，则只需将变化的部分加入到header帧中，改变的部分会加入到头部字段表中，首部表在 http 2.0 的连接存续期内始终存在,由客户端和服务器共同渐进地更新。

http 2.0关注的是首部压缩，而我们常用的gzip等是报文内容（body）的压缩。二者不仅不冲突，且能够一起达到更好的压缩效果。

压缩原理：

用header字段表里的索引代替实际的header。http/2 的 HPACK算法 使用一份索引表来定义常用的 http Header，把常用的 http Header 存放在表里，请求的时候便只需要发送在表里的索引位置即可。

### 请求的优先级（Request Priority）
把http消息分成很多独立帧之后，就可以通过优化这些帧的交错和传输顺序进一步优化性能。每个流都可以带有一个31比特的优先值：0 表示最高优先级；2的31次方-1 表示最低优先级。
- 优先级最高： 主要的html
- 优先级高： CSS文件
- 优先级中： js文件
- 优先级低： 图片

### 服务器推送（Server Push）
服务器可以对一个客户端请求发送多个响应。服务器向客户端推送资源无需客户端明确地请求。

服务端推送能把客户端所需要的资源伴随着index.html一起发送到客户端，省去了客户端重复请求的步骤。（一些静态资源可以极大地提高速度）

如果一个请求是由你的主页发起的，服务器很可能会响应主页内容、logo 以及样式表，因为它知道客户端会用到这些东西。

服务器推送还有一个很大的优势：可以缓存！也让在遵循同源的情况下，不同页面之间可以共享缓存资源成为可能。

注意两点：1.推送遵循同源策略。2.这种服务端的推送是基于客户端的请求响应来确定的。

### http瓶颈
现在所有的压力集中在底层一个TCP连接之上，TCP很可能就是下一个性能瓶颈，比如TCP分组的队首阻塞问题，单个TCP packet丢失导致整个连接阻塞，无法逃避，此时所有消息都会受到影响。


